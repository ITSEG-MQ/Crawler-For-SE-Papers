{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from html.parser import HTMLParser\n",
    "\n",
    "from time import sleep\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TOSEM', 'journal', 'https://dblp.uni-trier.de/db/journals/tosem/\\n']\n",
      "['TSE', 'journal', 'https://dblp.uni-trier.de/db/journals/tse/\\n']\n",
      "['IST', 'journal', 'https://dblp.uni-trier.de/db/journals/infsof/\\n']\n",
      "['JSS', 'journal', 'https://dblp.uni-trier.de/db/journals/jss/\\n']\n",
      "['ESE', 'journal', 'https://dblp.uni-trier.de/db/journals/ese/\\n']\n",
      "['SPE', 'journal', 'https://dblp.uni-trier.de/db/journals/spe/\\n']\n",
      "['STVR', 'journal', 'https://dblp.uni-trier.de/db/journals/stvr/\\n']\n",
      "['ASE journals', 'journal', 'https://dblp.uni-trier.de/db/journals/ase/\\n']\n",
      "['ICSE', 'conf', 'https://dblp.uni-trier.de/db/conf/icse/\\n']\n",
      "['FSE', 'conf', 'https://dblp.uni-trier.de/db/conf/sigsoft/\\n']\n",
      "['ASE conf', 'conf', 'https://dblp.uni-trier.de/db/conf/kbse/\\n']\n",
      "['ISSTA', 'conf', 'https://dblp.uni-trier.de/db/conf/issta/\\n']\n",
      "['ECOOP', 'conf', 'https://dblp.uni-trier.de/db/conf/ecoop/\\n']\n",
      "['ICPC', 'conf', 'https://dblp.uni-trier.de/db/conf/iwpc/\\n']\n",
      "['SANER', 'conf', 'https://dblp.uni-trier.de/db/conf/wcre/\\n']\n",
      "['ICSME', 'conf', 'https://dblp.uni-trier.de/db/conf/icsm/\\n']\n",
      "['VMCAI', 'conf', 'https://dblp.uni-trier.de/db/conf/vmcai/\\n']\n",
      "['ISSRE', 'conf', 'https://dblp.uni-trier.de/db/conf/issre/\\n']\n",
      "['ICST', 'conf', 'https://dblp.uni-trier.de/db/conf/icst/\\n']\n",
      "['SCAM', 'conf', 'https://dblp.uni-trier.de/db/conf/scam/\\n']\n",
      "['ATVA', 'conf', 'https://dblp.uni-trier.de/db/conf/atva/\\n']\n",
      "['MSR', 'conf', 'https://dblp.uni-trier.de/db/conf/msr/\\n']\n",
      "['APLAS', 'conf', 'https://dblp.uni-trier.de/db/conf/aplas/\\n']\n",
      "['PASTE', 'conf', 'https://dblp.uni-trier.de/db/conf/paste/\\n']\n",
      "['COMPSAC', 'conf', 'https://dblp.uni-trier.de/db/conf/compsac/\\n']\n",
      "['GECCO', 'conf', 'https://dblp.uni-trier.de/db/conf/gecco/\\n']\n",
      "['SSBSE', 'conf', 'https://dblp.uni-trier.de/db/conf/ssbse/\\n']\n",
      "['QRS', 'conf', 'https://dblp.uni-trier.de/db/conf/qrs/']\n"
     ]
    }
   ],
   "source": [
    "#手工输入会议以及链接\n",
    "# \"\"\"GECCO, SSBSE, QRS还没找到\"\"\"\n",
    "\n",
    "journals = []\n",
    "confs = []\n",
    "for line in open(\"conf_list.csv\"):\n",
    "    line = line.replace(\"http://\",\"https://\").replace(\"/index.html\",\"/\")\n",
    "    data = line.split(\"\\t\")\n",
    "    if data[1] == \"journal\":\n",
    "        journals.append((data[0],data[2].replace(\"\\n\",\"\")))\n",
    "    elif data[1] == \"conf\":\n",
    "        confs.append((data[0],data[2].replace(\"\\n\",\"\")))\n",
    "    print(line.split(\"\\t\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#先按照链接获取到dblp里面对应的journal所有volume的链接\n",
    "#再进入各个卷的链接，获取全部文章"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Journals: 100%|██████████████████████████████████████████████████████████████████████████| 8/8 [00:17<00:00,  2.21s/it]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import re\n",
    "\n",
    "volums_jour = []\n",
    "for journal, link in tqdm(journals,\"Journals\"):\n",
    "    r = requests.get(link, headers={\"Connection\": \"close\"})\n",
    "    if r.status_code == 200:\n",
    "        html = r.text\n",
    "    else:\n",
    "        print(r.status_code)\n",
    "    r.close()\n",
    "    sleep(0.01)\n",
    "    \n",
    "    bs = BeautifulSoup(html,\"html.parser\")\n",
    "    for item in bs.find_all(\"li\"):\n",
    "        if item.attrs == {} and item.a != None and item.img == None and item.a.attrs['href'].startswith(link):\n",
    "            year = re.findall('\\d{4}', item.text.split('\\n')[0], flags=0)[0]\n",
    "            for a in item.find_all('a'):\n",
    "                vol = re.findall('\\d+', a.text.replace(year, \"\"), flags=0)[0]\n",
    "                volums_jour.append((journal, year, vol, a.attrs['href']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Journal: 100%|███████████████████████████████████████████████████████████████████████| 495/495 [12:21<00:00,  1.50s/it]\n"
     ]
    }
   ],
   "source": [
    "jour_paper_list = []\n",
    "for conf, year, conf_det, href in tqdm(volums_jour,\"Journal\"):\n",
    "    r = requests.get(href, headers={\"Connection\": \"close\"})\n",
    "    if r.status_code == 200:\n",
    "        html = r.text\n",
    "    else:\n",
    "        print(r.status_code)\n",
    "    r.close()\n",
    "    sleep(0.01)\n",
    "\n",
    "    bs = BeautifulSoup(html,\"html.parser\")\n",
    "    first = True\n",
    "    for item in bs.find_all(\"cite\"):\n",
    "        for title in item.find_all(\"span\", \"title\"):\n",
    "            if first:\n",
    "                first = False\n",
    "            else:\n",
    "                jour_paper_list.append((conf, year, conf_det, title.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#先按照链接获取到dblp里面对应的conference所有track的链接\n",
    "#再进入各个卷的链接，获取全部文章"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Conferences: 100%|█████████████████████████████████████████████████████████████████████| 20/20 [00:49<00:00,  2.46s/it]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import re\n",
    "\n",
    "volums_conf = []\n",
    "for conf, link in tqdm(confs,\"Conferences\"):\n",
    "    r = requests.get(link, headers={\"Connection\": \"close\"})\n",
    "    if r.status_code == 200:\n",
    "        html = r.text\n",
    "    else:\n",
    "        print(r.status_code)\n",
    "    r.close()\n",
    "    sleep(0.01)\n",
    "    \n",
    "    bs = BeautifulSoup(html,\"html.parser\")\n",
    "    for item in bs.find_all(\"cite\"):\n",
    "        if item.find(\"span\", itemprop=\"publisher\"):\n",
    "            publisher = item.find(\"span\", itemprop=\"publisher\").text\n",
    "        else:\n",
    "#             print(item)\n",
    "            break\n",
    "        year = item.find(\"span\", itemprop=\"datePublished\").text\n",
    "\n",
    "        for title in item.find_all(\"span\", \"title\"):\n",
    "            href = list(title.next_siblings)[-1].attrs[\"href\"]\n",
    "        volums_conf.append((conf, year, publisher, title.text, href))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Conferences: 100%|███████████████████████████████████████████████████████████████████| 532/532 [15:43<00:00,  1.77s/it]\n"
     ]
    }
   ],
   "source": [
    "conf_paper_list = []\n",
    "for conf, year, publisher, conf_det, href in tqdm(volums_conf,\"Conferences\"):\n",
    "    r = requests.get(href, headers={\"Connection\": \"close\"})\n",
    "    if r.status_code == 200:\n",
    "        html = r.text\n",
    "    else:\n",
    "        print(r.status_code)\n",
    "    r.close()\n",
    "    sleep(0.01)\n",
    "\n",
    "    bs = BeautifulSoup(html,\"html.parser\")\n",
    "    first = True\n",
    "    for item in bs.find_all(\"cite\"):\n",
    "        for title in item.find_all(\"span\", \"title\"):\n",
    "            if first:\n",
    "                first = False\n",
    "            else:\n",
    "                conf_paper_list.append((conf, year, publisher, conf_det, title.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17653"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jour_paper_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33787"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(conf_paper_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#储存全部的文章列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = open(\"conf_paper_list.csv\", 'w', encoding=\"utf-8\")\n",
    "for conf, year, publisher, conf_det, title in conf_paper_list:\n",
    "    line = \"{}\\t{}\\t{}\\t{}\\t{}\\n\".format(conf, year, publisher, conf_det, title)\n",
    "    writer.write(line)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = open(\"jour_paper_list.csv\", 'w', encoding=\"utf-8\")\n",
    "for conf, year, conf_det, title in jour_paper_list:\n",
    "    line = \"{},{},{},{}\\n\".format(conf, year, conf_det, title)\n",
    "    writer.write(line)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_paper_list = []\n",
    "for line in open(\"conf_paper_list.csv\", encoding=\"utf-8\"):\n",
    "    line = line.replace(\"\\n\",\"\")\n",
    "    \n",
    "    conf = line.split(\"\\t\")[0]\n",
    "    year = line.split(\"\\t\")[1]\n",
    "    publisher = line.split(\"\\t\")[2]\n",
    "    conf_det = line.split(\"\\t\")[3]\n",
    "    title = line.split(\"\\t\")[-1]\n",
    "    conf_paper_list.append((conf, year, publisher, conf_det, title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "jour_paper_list = []\n",
    "for line in open(\"jour_paper_list.csv\", encoding=\"utf-8\"):\n",
    "    line = line.replace(\"\\n\",\"\")\n",
    "    \n",
    "    conf = line.split(\",\")[0]\n",
    "    year = line.split(\",\")[1]\n",
    "    conf_det = line.split(\",\")[2]\n",
    "    title = line.split(\",\")[3]\n",
    "    jour_paper_list.append((conf, year, conf_det, title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#筛选并存储"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\n",
    "    \"deep learning\",  \n",
    "    \"neural network\",\n",
    "    \"dnn\", \n",
    "    \"cnn\",\n",
    "    \"machine learning\",\n",
    "    \n",
    "    \"autonomous vehicle\", \n",
    "    \"autonomous driving\",\n",
    "    \"self-driving\", \n",
    "    \"automatics\",\n",
    "    \"autonomous car\",\n",
    "    \"driver assistance\",\n",
    "    \"adas\",\n",
    "    \"self driving\",\n",
    "    \"overtaking\",\n",
    "    \"automated vehicle\",\n",
    "    \"automated driving\",\n",
    "    \"automated car\",\n",
    "    \"driving scenarios\",\n",
    "    \"vehicle safety\",\n",
    "    \"intelligent vehicle\",\n",
    "    \"intelligent car\",\n",
    "    \"apollo\",\n",
    "    \"waymo\",\n",
    "    \"vehicle signalization system\",\n",
    "    \"pedestrian\",\n",
    "    \"lane\",\n",
    "    \"carla\",\n",
    "    \"lgsvl\",\n",
    "    \"vehicle\",\n",
    "    \"v2x\",\n",
    "    \"autonomous electric vehicle\",\n",
    "    \"autonomous electric car\",\n",
    "    \"connected vehicle\",\n",
    "    \"object detection\",\n",
    "    \"lidar\",\n",
    "    \"traffic scene\",\n",
    "    \"traffic accident\",\n",
    "    \"driving simulator\",\n",
    "    \"vision-based control systems\"\n",
    "]\n",
    "keywords_dict = {}\n",
    "for keyword in keywords:\n",
    "    keywords_dict[keyword] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keywords = [\n",
    "#     \"autonomous vehicle\", \n",
    "#     \"autonomous driving\",\n",
    "#     \"self-driving\", \n",
    "#     \"automatics\",\n",
    "#     \"autonomous car\",\n",
    "#     \"driver assistance\",\n",
    "#     \"adas\",\n",
    "#     \"self driving\",\n",
    "#     \"vechicle\",\n",
    "\n",
    "#     \"overtaking\",\n",
    "#     \"automated vehicle\",\n",
    "#     \"automated driving\",\n",
    "#     \"automated car\",\n",
    "#     \"driving scenarios\",\n",
    "#     \"vehicle safety\",\n",
    "#     \"intelligent vehicle\",\n",
    "#     \"intelligent car\",\n",
    "#     \"apollo\",\n",
    "#     \"waymo\",\n",
    "#     \"vehicle signalization system\",\n",
    "#     \"pedestrian\",\n",
    "#     \"carla\",\n",
    "#     \"lgsvl\",\n",
    "#     \"v2x\",\n",
    "#     \"autonomous electric vehicle\",\n",
    "#     \"autonomous electric car\",\n",
    "#     \"connected vehicle\",\n",
    "#     \"object detection\",\n",
    "#     \"traffic scene\",\n",
    "#     \"traffic accident\",\n",
    "#     \"driving simulator\",\n",
    "#     \"vision-based control systems\"\n",
    "# ]\n",
    "# keywords_dict = {}\n",
    "# for keyword in keywords:\n",
    "#     keywords_dict[keyword] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_paper_filt = []\n",
    "for conf, year, publisher, conf_det, title in conf_paper_list:\n",
    "    if int(year) > 2015:\n",
    "        filted = True\n",
    "        for keyword in keywords:\n",
    "            if keyword in title.lower():\n",
    "                filted = False\n",
    "                for words in [\"by deep learning\", \"using deep learning\", \n",
    "                             \"by machine learning\", \"using machine learning\", \n",
    "                             \"by cnn\", \"using cnn\", \n",
    "                             \"by dnn\", \"using dnn\"]:\n",
    "                    if words in title.lower():\n",
    "                        filted = True\n",
    "                    if not filted:\n",
    "                        keywords_dict[keyword] += 1\n",
    "        if not filted:\n",
    "            conf_paper_filt.append((conf, year, publisher, conf_det, title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = open(\"conf_paper_filt.tsv\", 'w', encoding=\"utf-8\")\n",
    "for conf, year, publisher, conf_det, title in conf_paper_filt:\n",
    "    line=\"{}\\t{}\\t{}\\t{}\\t{}\\n\".format(conf, year, publisher, conf_det, title)\n",
    "    writer.write(line)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "536"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(conf_paper_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "jour_paper_filt = []\n",
    "for jour, year, jour_det, title in jour_paper_list:\n",
    "    if int(year) > 2015:\n",
    "        filted = True\n",
    "        for keyword in keywords:\n",
    "            if keyword in title.lower():\n",
    "                filted = False\n",
    "                for words in [\"by deep learning\", \"using deep learning\", \n",
    "                             \"by machine learning\", \"using machine learning\", \n",
    "                             \"by cnn\", \"using cnn\", \n",
    "                             \"by dnn\", \"using dnn\"]:\n",
    "                    if words in title.lower():\n",
    "                        filted = True\n",
    "                    if not filted:\n",
    "                        keywords_dict[keyword] += 1\n",
    "        if not filted:\n",
    "            jour_paper_filt.append((jour, year, jour_det, title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jour_paper_filt = []\n",
    "# for jour, year, jour_det, title in jour_paper_list:\n",
    "#     if int(year) > 2015:\n",
    "#         filted = True\n",
    "#         for keyword in keywords:\n",
    "#             if keyword in title.lower():\n",
    "#                 filted = False\n",
    "#                 keywords_dict[keyword] += 1\n",
    "#         if not filted:\n",
    "#             jour_paper_filt.append((jour, year, jour_det, title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = open(\"jour_paper_filt.tsv\", 'w', encoding=\"utf-8\")\n",
    "for jour, year, conf_det, title in jour_paper_filt:\n",
    "    line=\"{}\\t{}\\t{}\\t{}t\\n\".format(jour, year, jour_det, title)\n",
    "    writer.write(line)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jour_paper_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deep learning': 1032,\n",
       " 'neural network': 1616,\n",
       " 'dnn': 128,\n",
       " 'cnn': 120,\n",
       " 'machine learning': 1282,\n",
       " 'autonomous vehicle': 128,\n",
       " 'autonomous driving': 160,\n",
       " 'self-driving': 40,\n",
       " 'automatics': 0,\n",
       " 'autonomous car': 24,\n",
       " 'driver assistance': 8,\n",
       " 'adas': 8,\n",
       " 'self driving': 0,\n",
       " 'overtaking': 0,\n",
       " 'automated vehicle': 24,\n",
       " 'automated driving': 48,\n",
       " 'automated car': 0,\n",
       " 'driving scenarios': 8,\n",
       " 'vehicle safety': 0,\n",
       " 'intelligent vehicle': 0,\n",
       " 'intelligent car': 0,\n",
       " 'apollo': 8,\n",
       " 'waymo': 0,\n",
       " 'vehicle signalization system': 0,\n",
       " 'pedestrian': 41,\n",
       " 'lane': 80,\n",
       " 'carla': 0,\n",
       " 'lgsvl': 0,\n",
       " 'vehicle': 464,\n",
       " 'v2x': 8,\n",
       " 'autonomous electric vehicle': 0,\n",
       " 'autonomous electric car': 0,\n",
       " 'connected vehicle': 8,\n",
       " 'object detection': 24,\n",
       " 'lidar': 0,\n",
       " 'traffic scene': 0,\n",
       " 'traffic accident': 0,\n",
       " 'driving simulator': 0,\n",
       " 'vision-based control systems': 8}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = open(\"keyword.tsv\",\"w\",encoding=\"utf-8\")\n",
    "for keyword in keywords_dict:\n",
    "    writer.write(\"{}\\t{}\\n\".format(keyword, keywords_dict[keyword]))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
